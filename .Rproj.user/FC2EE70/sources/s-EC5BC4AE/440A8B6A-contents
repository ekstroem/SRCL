---
title: 'Causes of Outcome Learning'
subtitle: 'Given a particular health outcome, what are the various sets of events which might have been its causes?'
author:
- A Rieckmann^[Section of Epidemiology, Department of Public Health, University of Copenhagen]
- P Dworzynski^[Novo Nordisk Foundation Center for Basic Metabolic Research, University of Copenhagen]
- L Arras^[Machine Learning Group, Department of Video Coding & Analytics, Fraunhofer Heinrich Hertz Institute]
- S Lapuschkin^‡
- W Samek^‡
- O Arah^[Department of Epidemiology, Fielding School of Public Health, University of California, Los Angeles and Department of Statistics, UCLA College of Letters and Science, Los Angeles]
- NH Rod^*
- CT Ekstrøm^[Section of Biostatistics, Department of Public Health, University of Copenhagen]
date: "Suggested journal: Epidemiology. Date: `r format(Sys.time(), '%d.%m.%Y')`"
output:
  pdf_document:
    highlight: tango
    number_sections: yes
    toc: no
    toc_depth: 2
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
classoption: onecolumn
editor_options:
  chunk_output_type: console
csl: epidemiology.csl
header-includes: 
  \usepackage{float} \floatplacement{figure}{htbp} 
references:
  
- author:
  - family: Smith
  container-title: IJE
  id: Smith2019
  issued:
    year: 2019
  title: Post-Modern Epidemiology - When Methods Meet Matter
  type: article-journal
- author:
  - family: Rothman
  container-title: American journal of epidemiology
  id: rothman1976
  issued:
    year: 1976
  title: Causes
  type: article-journal
- author:
  - family: VanderWeele et al.
  container-title: AJE
  id: VanderWeele2007
  issued:
    year: 2007
  title: Directed acyclic graphs, sufficient causes, and the properties of conditioning
    on a common effect
  type: article-journal
- author:
  - family: VanderWeele
  container-title: Oxford University Press
  id: vanderweele2015
  issued:
    year: 2015
  title: Explanation in Causal Inference - Methods for Mediation and Interaction
  type: book
- author:
  - family: Montavon et al.
  container-title: Digital Signal Processing
  id: Montavon2018
  issued:
    year: 2018
  title: Methods for interpreting and understanding deep neural networks
  type: article-journal
- author:
  - family: Montavon et al.
  container-title: Pattern Recognition
  id: Montavon2017
  issued:
    year: 2017
  title: Explaining nonlinear classification decisions with deep Taylordecomposition
  type: article-journal
- author:
  - family: Yang et al.
  container-title: IEEE
  id: Yang2018
  issued:
    year: 2018
  title: Explaining Therapy Predictions with Layer-wise Relevance Propagation in Neural
    Networks
  type: article-journal
- author:
  - family: Arras et al.
  container-title: PLoS ONE
  id: Arras2017
  issued:
    year: 2017
  title: What is relevant in a text document? - An interpretable machine learning
    approach
  type: article-journal
- author:
  - family: Samek et al.
  container-title: IEEE
  id: Samek2016
  issued:
    year: 2016
  title: Evaluating the visualization of what a Deep Neural Network has learned
  type: article-journal
- author:
  - family: Sturm et al.
  container-title: Journal of Neuroscience Methods
  id: Sturm2016
  issued:
    year: 2016
  title: Interpretable Deep Neural Networks for Single-Trial EEG Classification
  type: article-journal
- author:
  - family: Morris
  container-title: BMJ
  id: Morris1955
  issued:
    year: 1955
  title: Uses of Epidemiology
  type: article-journal
- author:
  - family: Tsai et al.
  container-title: The Lancet
  id: tsai2017
  issued:
    year: 2017
  title: Co-occurring epidemics, syndemics, and population health
  type: article-journal
- author:
  - family: Shonkoff et al.
  container-title: Pediatrics
  id: shonkoff2012
  issued:
    year: 2012
  title: The Lifelong Effects of Early Childhood Adversity and Toxic Stress
  type: article-journal
- author:
  - family: Rose
  container-title: Oxford Medical Publicatiosn
  id: rose1992
  issued:
    year: 1992
  title: The Strategy of Preventive Medicine
  type: article-journal
- author:
  - family: Wild
  container-title: IJE
  id: wild2012
  issued:
    year: 2012
  title: The exposome - from concept to utility
  type: article-journal
- author:
  - family: Rappaport & Smith
  container-title: Science
  id: rappaport2010
  issued:
    year: 2010
  title: Environment and Disease Risks
  type: article-journal
- author:
  - family: Rappaport
  container-title: Journal of Exposure Science and Environmental Epidemiology
  id: rappaport2011
  issued:
    year: 2010
  title: Implications of the exposome for exposure science
  type: article-journal
- author:
  - family: Patel et al.
  container-title: Plos One
  id: patel2010
  issued:
    year: 2010
  title: An Environment-Wide Association Study (EWAS) on Type 2 Diabetes Mellitus
  type: article-journal
- author:
  - family: Patel et al.
  container-title: AIDS
  id: patel2018
  issued:
    year: 2018
  title: Systematic identification of correlates of HIV infection - an X-wide association
    study
  type: article-journal
- author:
  - family: Ioannidis
  container-title: Epidemiology
  id: ioannidis2015
  issued:
    year: 2015
  title: Exposure‐wide epidemiology - revisiting Bradford Hill
  type: article-journal
- author:
  - family: VanderWeele
  container-title: Epidemiology
  id: vanderweele2017
  issued:
    year: 2017
  title: Outcome-wide Epidemiology
  type: article-journal
- author:
  - family: Hernán et al.
  container-title: American Journal of Epidemiology
  id: hernan2002
  issued:
    year: 2002
  title: Causal Knowledge as a Prerequisite for Confounding Evaluation - An Application
    to Birth Defects Epidemiology
  type: article-journal
- author:
  - family: Hernan, Robins
  container-title: Unpublished
  id: hernan2019
  issued:
    year: 2019
  title: Causal inference
  type: article-journal
- author:
  - family: Pearl, Glymour, Jewell
  container-title: Wiley
  id: pearl2016
  issued:
    year: 2016
  title: Causal inference in Statistics - A Primer
  type: book
- author:
  - family: He et al.
  container-title: arXiv
  id: he2015
  issued:
    year: 2015
  title: Deep Residual Learning for Image Recognition
  type: article-journal
- author:
  - family: Pearl
  container-title: Communications of the ACM
  id: pearl2019
  issued:
    year: 2019
  title: The Seven Tools of Causal Inference, with Reflections on Machine Learning
  type: article-journal
- author:
  - family: Bach et al.
  container-title: PLoS ONE
  id: bach2015
  issued:
    year: 2015
  title: On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise
    Relevance Propagation
  type: article-journal
- author:
  - family: Samek et al.
  container-title: Springer
  id: samek2019
  issued:
    year: 2019
  title: Explainable AI - Interpreting, Explaining and Visualizing Deep Learning, pages 193-209. Chapter - Layer-Wise Relevance Propagation  An Overview
  type: book
- author:
  - family: Eide et al.
  container-title: Springer
  id: eide2001
  issued:
    year: 2001
  title: Attributable fractions - fundamental concepts and their visualization
  type: article-journal
- author:
  - family: Lawlor et al.
  container-title: IJE
  id: lawlor2016
  issued:
    year: 2016
  title: Triangulation in aetiological epidemiology
  type: article-journal
- author:
  - family: Bengtsson et al.
  container-title: BMJ Open
  id: bengtsson2019
  issued:
    year: 2019
  title: Cohort profile - the DANish LIFE course (DANLIFE) cohort, a prospective register-based
    cohort of all children born in Denmark since 1980
  type: article-journal
- author:
  - family: VanderWeele and Tchetgen
  container-title: Epidemiology
  id: vanderweele2015_2
  issued:
    year: 2015
  title: Attributing effects to interactions
  type: article-journal
- author:
  - family: Greenland and Robins
  container-title: American Journal of Epidemiology
  id: greenland1988
  issued:
    year: 1988
  title: Conceptual problems in the definition and interpretation of attributable
    fractions
  type: article-journal
- author:
  - family: Krieger
  container-title: Soc Sci Med
  id: krieger1994
  issued:
    year: 1994
  title: Epidemiology and the web of causation - Has anyone seen the spider?
  type: article-journal
- author:
  - family: Hill
  container-title: Proceedings ofthe Royal Society of Medicine
  id: hill1965
  issued:
    year: 1965
  title: The Environment and Disease - Association or Causation?
  type: article-journal
- author:
  - family: Olsen and Jensen
  container-title: European Journal of Epidemiolog
  id: olsen2019
  issued:
    year: 2019
  title: Causal criteria - time has come for a revision
  type: article-journal
- author:
  - family: Smith et al.
  container-title: International Journal of Epidemiolog
  id: smith2016
  issued:
    year: 2016
  title: A structured approach to hypotheses involving continuous exposures over the
    life course
  type: article-journal
- author:
  - family: Reimers et al.
  container-title: 9th International workshop on climate informatics
  id: reimers2019
  issued:
    year: 2019
  title: Using causal inference to globally understand black box predictors beyond saliency maps
  type: article-journal
- author:
  - family: Brankovic et al.
  container-title: European Journal of Clinical Investigation
  id: brankovic2019
  issued:
    year: 2019
  title: Understanding of interaction (subgroup) analysis in clinical trials
  type: article-journal
- author:
  - family: Shrikumar et al.
  container-title: arXiv
  id: shrikumar2019
  issued:
    year: 2019
  title: Deep lift - Learning Important Features Through Propagating Activation Difference
  type: article-journal
- author:
  - family: Yurochkin et al.
  container-title: 31st Conference on Neural Information Processing Systems 
  id: yurochkin2017
  issued:
    year: 2017
  title: Multi-way Interacting Regression via Factorization Machines
  type: article-journal  
- author:
  - family: Ansarifar et al.
  container-title: Bioinformatics 
  id: ansarifar2019
  issued:
    year: 2019
  title:  New algorithms for detecting multi-effect and multi-way epistatic interactions
  type: article-journal 
- author:
  - family: Peters et al.
  container-title: The MIT Press 
  id: peters2017
  issued:
    year: 2017
  title:  Elements of Causal Inference - Foundations and Learning Algorithms
  type: article-journal 
- author:
  - family: Frye et al.
  container-title: arXiv
  id: frye2019
  issued:
    year: 2019
  title: Asymmetric Shapley values - incorporating causal knowledge into model-agnostic explainability
  type: article-journal 
- author:
  - family: Tzoulaki et al.
  container-title: Circulation
  id: tzoulaki2012
  issued:
    year: 2012
  title: A Nutrient-Wide Association Study on Blood Pressure
  type: article-journal 
- author:
  - family: Patel et al.
  container-title: American Journal of Epidemiology
  id: patel2015
  issued:
    year: 2015
  title: Systematic Assessment of the Correlations of Household Income With Infectious, Biochemical, Physiological, and Environmental Factors in the United States, 1999–2006
  type: article-journal 
- author:
  - family: Patel et al.
  container-title: International Journal of Epidemiology
  id: patel2012
  issued:
    year: 2012
  title: Systematic evaluation of environmental factors - persistent pollutants and nutrients correlated with serum lipid levels
  type: article-journal
- author:
  - family: Ngamwong et al.
  container-title: Plos ONE
  id: ngamwong2015
  issued:
    year: 2015
  title: Additive Synergism between Asbestos and Smoking in Lung Cancer Risk - A Systematic Review and Meta-Analysis
  type: article-journal
- author:
  - family: Murtagh et al.
  container-title: Journal of Classification
  id: murtagh2014
  issued:
    year: 2014
  title: Ward’s Hierarchical Agglomerative Clustering Method - Which Algorithms Implement Ward’s Criterion?
  type: article-journal
- author:
  - family: Tennant et al.
  container-title: medRxiv preprint
  id: tennant2019
  issued:
    year: 2019
  title: Use of directed acyclic graphs (DAGs) in applied health research - review and recommendations
  type: article-journal 
- author:
  - family: Ribeiro et al.
  container-title: arXiv
  id: ribeiro2016
  issued:
    year: 2016
  title: Why Should I Trust You? - Explaining the Predictions of Any Classifier
  type: article-journal 
- author:
  - family: Koo et al.
  container-title: BioMed research international
  id: koo2013
  issued:
    year: 2013
  title: A review for detecting gene-gene interactions using machine learning methods in genetic epidemiology
  type: article-journal 
- author:
  - family: Sundararajan et al.
  container-title: arXiv
  id: sundararajan2017
  issued:
    year: 2017
  title: Axiomatic Attribution for Deep Networks
  type: article-journal 
- author:
  - family: Fong et al.
  container-title: arXiv
  id: fong2017
  issued:
    year: 2017
  title: Interpretable Explanations of Black Boxes by Meaningful Perturbation
  type: article-journal 
- author:
  - family: Zeiler et al.
  container-title: arXiv
  id: zeiler2013
  issued:
    year: 2013
  title: Visualizing and Understanding Convolutional Networks
  type: article-journal 
- author:
  - family: Beam et al.
  container-title: JAMA
  id: beam2020
  issued:
    year: 2020
  title: Challenges to the Reproducibility of Machine Learning Models in Health Care
  type: article-journal
- author:
  - family: VanderWeele et al.
  container-title: IJE
  id: vanderweele2006
  issued:
    year: 2006
  title: From counterfactuals to sufficient component causes and vice versa
  type: article-journal
- author:
  - family: Holzinger et al.
  container-title: Wiley Interdisciplinary Reviews - Data Mining and Knowledge Discovery
  id: holzinger2019
  issued:
    year: 2019
  title: Causability and explainability of artificial intelligence in medicine
  type: article-journal
- author:
  - family: Lanza et al.
  container-title: Struct Equ Modeling
  id: lanza2013
  issued:
    year: 2013
  title: Latent Class Analysis With Distal Outcomes - A Flexible Model-Based Approach
  type: article-journal
- author:
  - family: Rieckmann et al.
  container-title: Submitted
  id: rieckmann2020
  issued:
    year: 
  title: Machine Learning models aimed at identifying risk factors for reducing morbidity and mortality may need to consider confounding such as calendar time
  type: article-journal
- author:
  - family: Rod et al.
  container-title: The Lancet (accepted)
  id: rod2020
  issued:
    year: 2020
  title: Trajectories of childhood adversity and mortality in early adulthood - A population-based cohort study
  type: article-journal  
      
abstract: Nearly all diseases are multifactorial i.e. diseases are caused not by a single exposure but, potentially, several combinations of different exposures. Yet, most epidemiological studies focus on the average causal effect of a single exposure for an outcome. We suggest the Causes of Outcome Learning approach for epidemiological studies that intends to learn the various combinations of exposures (causes, if all assumptions are met) responsible for why certain sub-groups have a higher-than-normal risk of disease. The approach allows for exposures acting alone and in synergy with others. With the assumption that exposures either have no effect or always act in the same direction (the monotonicity assumption), we suggest an approach with three phases which inclues; 1) proposing a causal model, 2) fitting a monotonistic model on an additive scale, decomposing risk contributions, and cluster individuals based on risk contributions into sub-groups, 3) and finally hypothesis development and testing in new data e.g. by triangulation. Phase two is the core added value, where we suggest using a monotonistic neural network and Layer-wise Relevance Propagation for the model and decomposition. We demonstrate the approach on synthetic data using the provided R package ‘CoOL’ for phase 2. The approach is focused on binary exposures and outcomes, but may be extended to other measurement types. We hope this approach will encourage epidemiologists to study the distribution of causes of an outcome in order to eventually develop more effective, targeted, and informed public health interventions.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.pos = "H")
options(tinytex.verbose = TRUE)
library(knitr)
#source("/Volumes/Macintosh HD/Users/ANRI/Google Drev/gdrive - SCL/SCL_functions.R")

#source("C:/Users/lvb917/Google Drev/gdrive - SCL/SCL_functions.R")
#library(SCL)


#setwd("/Volumes/Macintosh HD/Users/ANRI/Google Drev/gdrive - SCL/Manuscripts/Epi paper/")
#setwd("C:/Users/anri/Google Drev/gdrive - SCL/Manuscripts/Epi paper/")
setwd("C:/Users/lvb917/Google Drev/gdrive - SCL/Manuscripts/Epi paper/") # ku computer


set.seed(3216)

```



# Introduction
Nearly all diseases are multifactorial i.e. they may be caused by several different combinations of exposures. Thus, understanding the spectra of exposures rather than single exposures for effective preventive strategies has been elementary in epidemiology for decades. Rose stated in The Strategy of Preventive Medicine (1993) that "*... risk assessment must consider all relevant factors together rather than confine attention to a single test, for nearly all diseases are multifactorial.*" when discussing effective policy decisions [@rose1992]. With this paper, we introduce an approach that attempts to answer the question *"Given a particular health outcome, what are the various sets of events which might have been its causes?"*, rather than the most often asked question in epidemiolgy about average causal effects of single exposures: *"What would have occurred if a particular factor were intervened upon and thus set to a different level than it in fact was?"* [@vanderweele2006].

Approaches such as the exposome [@wild2012; @rappaport2010; @rappaport2011] and exposure- or environment-wide association studies (EWAS) [@patel2010; @patel2018] have recently been suggested to assess multiple exposures simultaneously. Most studies using these approaches consider multiple single exposures without allowing for interactions [@patel2010; @patel2018; @tzoulaki2012;@patel2012]. The few that do tend to investigate interaction of selected factors [@patel2015]. Such studies have been discussed in relation to their potential, especially in light of successes of genome-wide association studies,[@ioannidis2015] and limitations such as a challenging causal interpretation [@vanderweele2017].

When studying multifactorial diseases, causes may act together and lead to a combined effect that is more than the sum of the individual effects. This is called synergism. One commonly referred example of synergism is how the combined effect of smoking and asbestos on lung cancer exceeds the sum of their individual effects [@ngamwong2015]. Theoretical frameworks related to synergistic effects of multiple causes exist, of which the most established framework in epidemiology is the sufficient component cause model [@rothman1976], which describes when combinations of component causes are sufficient to cause disease. This framework has been adapted into the causal inference literature [@VanderWeele2007]. Assessment of synergism between causes may give etiological insight on how to prevent and treat disease and it may help to identify high risk groups.

If "*risk assessment must consider all relevant factors together*", why are so few authors asking questions about causes of outcomes? We suspect it is due to frequently taught frameworks for epidemiologists that warn against type 1 errors from multiple testing [@brankovic2019], various confounding structures for each exposure [@vanderweele2017], and the overwhelming number of combinations between exposures that can be created [@hernan2019]. In this work, we introduce an approach for learning about the possible exposures which may have led to the health outcome, the Causes of Outcome Learning (CoOL) approach, and a corresponding R package. Based on synthetic data, we show how this approach identifies sub-groups of individuals whose shared combination of exposures caused them to have a higher-than-normal risk of the disease outcome. We also show that some classical approaches in epidemiology such as marginal effects of single exposures from causally adjusted models and classify-analyze approaches cannot identify these sub-groups. We explain how the 3 phases of CoOL can be part of a longer scientific process on exploring and justifying causal phenomena. We hope that CoOL will encourage epidemiologists to develop more effective, targeted, and informed public health interventions.

<!--
\color[rgb]{.93,.35,0}
\color[rgb]{144/255,26/255,30/255}
\color[rgb]{0.5647059,0.1019608,0.1176471} 
\color{black}
-->

# The CoOL approach
The CoOL approach is aimed at a classical epidemiological problem about identifying causes of an outcome. It is, however, enabled by three major new developments in the fields of machine learning (algorithms that learns patterns in data) and causal inference (inference about causal relations based on data and assumptions about the structure of data). Firstly, advances in computing and machine learning allow for identification of complex correlation structures (including synergism) in large datasets. Secondly, there has been a recent breakthrough in understanding why machine learning models produce the results they do (explainable AI such as Layer-Wise Relevance Propagation [LRP]) [@samek2019]. Lastly, by assuming a causal structure of data, models may be interpreted as structural causal models, which allows for causal interpretation [@pearl2016]. To ensure that the approach is embedded in an inductive and deductive scientific process, we suggest the following 3 phases, of which our contribution is related to phase 2, which is the computational part (Figure \ref{fig_overview}):

![The 3 phases of the CoOL approach towards inference to the best explanation. Researchers scope their research question and causal structure assumptions in phase 1. In phase 2, a monotonistic model is fitted, risk contributions are decomposed and clustered. The results are validated and held against other available sources in order to develop new hypotheses that can be tested and validated. New understandings will update our causal model. \label{fig_overview}](Figures/Overview of the 3 phases.jpg){width=100%}

1. Propose a causal model: Draw a causal Direct Acyclic Graph (DAG) of the exposures and the outcome based on prior domain expertise.
2. Fit a monotonistic neural network, decompose the risk contributions using LRP, cluster individuals based on the risk contributions on a testing data set, and ensure the robustness of the findings in a test data set. We provide the R package 'CoOL' for phase 2.
3. Based on the new findings and existing knowledge, develop hypotheses for further studies. The scientific process will continue in an inductive-deductive continuum towards inference to the best explanation.

## Phase 1: The causal model
In order to interpret associations as causal effects, we need to specify our knowledge about the data generating processes as a causal structure [@hernan2002; @hernan2019]. DAGs are one way to denote causal structures and allow for causal interpretation of associations given certain assumptions (as exchangeability, perfectly measured variables, positivity, no systematic censoring and the stability assumption)[@hernan2019] and are now commonly used in epidemiology [@tennant2019]. DAGs have also been used to conceptualize the sufficient component cause model [@VanderWeele2007]. The theoretical DAG can be shown in Figure \ref{fig_models}A, where $X_i$ denotes exposures, $S_k$ denotes *synergism-functions* i.e. unobserved mediators that can learn the combined effects of various exposures $X_i$, and $Y$ denotes the outcome. In order to learn the combinations of exposures (causes, if all assumptions are met) responsible for why certain sub-groups have a higher-than-normal risk of disease, we need a reference group. The reference group is defined by us not having any information of causes of their risk. Thus, they only have the baseline risk. The *monotonicity assumption* is used to ensure this i.e. each exposure, $X_i$, is assumed to have either has no effect or its effect always takes the same direction. Thus, if one combination of exposures has the lowest risk of the health outcome, then all effects for the remaining groups are either zero or positive. We suggest that the data is prepared so that all direct effects are positive but overruled by domain expertise. Following the convention established by VanderWeele[@VanderWeele2007], we denote the monotonicity assumption with a $+$. Given the causal structure is correct, the average causal effect, in the total population, for being exposed to combination $z$ of the exposures compared with the baseline risk is given by $P(Y_{X_z})-P(Y_{X_{baseline}})$, which can be estimated as $P(Y=1|X^+=z) - P(Y=1|X^+=0)$.

![A) An assumed causal model illustrated using a directed acyclic graph, where $X_i$ denotes the exposures, $S_j$ denotes *hidden* synergistic component causes, $Y$ denotes the outcome, and $+$ denotes monotonistic effects. B) A monotonistic neural network resemblig the causal model. $X_i^+$ denotes monotonistically coded exposures, $\beta_{i,j}^+$ denotes non-negative parameters, $S_j()$ denotes hidden synergism-functions, $-\alpha^+_j$ denotes non-positive intercepts, and $R^{b^+}$ denotes the baseline risk \label{fig_models}](Figures/combined_models.jpg){width=100%}



Decisions on whether to include distal and proximal causes influences the results, [@vanderweele2017] which is elaborated in the discussion. If we would like to adjust the monotonistic neural network for confounding (e.g. time and seasonality), we can add the confounder(s) as an exposure similarly as in any other regression [@rieckmann2020]. By including the confounder, we block the backdoor path through the confounder [@pearl2016].


<!--
\color[rgb]{.93,.35,0}
\color[rgb]{144/255,26/255,30/255}
\color[rgb]{0.5647059,0.1019608,0.1176471} 
\color{black}
-->

## Phase 2

### Fitting a monotonistic model \label{fitting}
We suggest using a constrained version of *neural networks* with three layers - an input layer with the exposures, a hidden layer with hidden mediators called synergism-functions, and an output layer with the health outcome. In this case, the neural network resembles a linear regression model but with two main modifications. First, the model includes a series of unobserved mediators that can learn the combined effects of various exposures. We call these hidden mediators the synergism-functions. Second, we restrict all parameters to have non-negative the value, which is called the monotonicity assumption. This *monotonistic single-hidden layer neural network* (Figure \ref{fig_models}B) is designed to resemble our DAG with hidden synergism-functions (Figure \ref{fig_models}A).

With this model, we intend to learn the various events which may have led to the health outcome. The model needs to be monotonistic and estimate the risk on an additive scale so that synergism is defined as combined effects that are larger than the sum of individual effects.[@rothman1976] The synergism-functions allow exposures to act alone or in combinations with others. We need to specify the number of synergism-functions (this sets the upper limit of possible sets of event combinations causing the outcome - too few synergism-functions will not allow us to capture all cause combinations and too many will increase the model fitting time). In Figure \ref{fig_models}B, $X_i^+$ denotes $i$ exposures (coded 0 and 1, where 1 compared with 0 is associated with a positive effect or no effect) and $Y$ denotes the disease outcome (coded 0 and 1). $\beta_{i,j}^+$ denotes parameters from the exposures to the synergism-functions (can only take non-negative values), $S_j^+()$ denotes $j$ synergism-functions, which each return the sum of its input value if it is positive, otherwise they return zero$^{footnote}$^[Commonly referred to as rectified linear units (ReLU)]. $-\alpha_j^+$ is an intercept (can effectively only take non-positive values) that ensures that no effect comes from the synergism-functions unless some exposure(s) affects it. $R_{baseline}^{+}$, estimates the baseline risk (can only take non-negative values).

The monotonistic neural network can be denoted as:

$$P(Y=1|X^+)=\sum_{j}\Big(S_j^+\big(\sum_{i}(X_i^+\cdot \beta_{i,j}^+) - \alpha_j^+\big)\Big) + R_{baseline}^{+}$$
Where the risk for the reference group is the baseline risk:

$$P(Y=1|X^+=0)= R_{baseline}^{+}$$

Fitting the model is done in a step-wise procedure one individual at a time, where the model estimates the individual's risk of the disease outcome, estimates this prediction's error ($\frac{(Y - P(Y|X^+))^2}{2}$) and adjusts the model parameters to reduce this error. By iterating through all individuals for multiple epochs (one complete iteration through all individuals is called an epoch),we obtain model parametrization which leads to the smallest sum of prediction errors across the entire population. The model fit follows the linear expectation that synergism is a combined effect larger than the sum of independent effects. The initial values, derivatives, and learning rates are described in further detail in the Supplementary material \ref{derivatives}. The monotonistic model ensures that the risk cannot be negative. 

We suggest splitting data into a train and test data set, such that findings from the train data set can be manually confirmed in the test data set before developing hypotheses. This procedure prevents type 1 errors from an overfitted model.

### Decomposing risk contributions
Machine learning models are commonly referred to as black boxes due to the limited interpretability of their parameters.[@pearl2019] For example, in neural networks it is particuarly challenging to interpret parameters due to their numbers and the models flexibility. For example, in a neural network, effects of exposures can take different paths and depends on the value of  other exposures. Instead of interpreting the model (and its parameters) directly, we use LRP [@bach2015; @Montavon2018; @samek2019] to decompose the overall risk of the outcome to *risk contributions* for each individual. These risk contributions may be interpreted as the exposures' positive contribution to the risk given the model and the individual's set of exposures. The original term for risk contributions in the LRP literature is *relevance measures*, but given our causal model assumptions, we can now interpret relevance measures as risk contributions.

The predicted risk of the outcome, $P(Y=1|X^+)$ is decomposed into a baseline risk, $R_{baseline}^+$, and the risk contributions by each exposure, $R^X_i$.$^{footnote}$^[For readers familiar with LRP, we use the $\alpha=1,\beta=0$-rule, where the decomposition only follows positive weights and ignores negative weights,[@bach2015; @Montavon2018]] so that each individual's risk of the outcome can be decomposed into:

$$P(Y=1|X^+)=R_{baseline}^++\sum_iR^X_i$$
*Where $P(Y=1|X^+)$ can take values between 0 and 1.*

The below procedure is conducted for all individuals in a one-by-one fashion. The baseline risk, $R_{baseline}^+$, is represented by its own parameter as illustrated in Figure \ref{fig_models}B. The decomposition of the risk contributions for exposures, $R^X_i$, takes 3 steps:

Step 1 - Subtract the baseline risk, $R^{b^+}$:

$$R^X_k =  P(Y=1|X^+)-R_{baseline}^+$$

Step 2 - Decompose risk contributions to the syngergism-functions: 

$$R^{X}_j =  \frac{S_j}{\sum_jS_j} R^X_k$$

<!--
$$R^X_j =  \frac{H_j e^{w_{j,k}}}{\sum_j(H_j e^{w_{j,k}})} \Big(P(Y=1|X)-f_k(b_k)\Big)$$
-->

*Where $S_j$ is the value returned by the synergism-functions, $S_j^+()$ given the exposure distribution $X_i^+$.*

Step 3 - Decompose risk contributions to the exposures:

$$R^{X}_i = \sum_j \Big(\frac{X_i^+ \cdot \beta_{i,j}^+}{\sum_i( X_i^+ \cdot \beta_{i,j}^+)}R^X_j\Big)$$

As a result of the risk decomposition each individual is assigned
risk contributions,$R^X_i$, equal to the number of exposures plus a baseline risk value. We call the combined matrix of the risk contributions for the full study population the *risk contribution matrix*. Thedecomposition of risk contributions can be illustrated as in Figure \ref{fig_lrp_flow} (row 1 and 2).

![Decomposing risk contributions (row 1 and 2) with ID B as the example and results from clustered sub-groups (row 3 and 4). The width of the arrows indicate the amount of information passed forward. The illustration with ID B shows that information is passed through the synergism-function, $S_1()$, but the synergism-function, $S_3()$, does not let information pass through, thus when decomposing the predicted risk, the risk contribution passes through $S_1()$ alone and not through $S_3()$. The dendrogram suggests 3 sub-groups. The prevalences and mean risks are shown by sub-group. The table visualize the mean risk contributions by the size for each sub-group. \label{fig_lrp_flow}](Figures/Flowchart.jpg){width=90%}


### Clustering of risk contributions
We sub-group the individuals based on risk contribution matrix. We recommend hierarchical clustering using Manhattan distances$^{footnote}$^[Manhattan distances and the Ward method are not unifiable - we are looking into whether the ward method can be modified - see https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0168288&type=printable] and the Ward method.[@murtagh2014] Clustering approaches such as k-means give highly unstable results and tend to miss sub-groups. While the presentation of the results depends on the study, we employ a dendrogram with node size representing the prevalence of similar risk contributions can be used to decide the number of sub-groups  (Figure \ref{fig_lrp_flow} row 3). We plot the prevalence and mean risk of each sub-groups (inspired by excess probability plots [@eide2001]) to help identify the sub-groups with a high public health impact (Figure \ref{fig_lrp_flow} row 3). We finally make a table of mean risk contribution and standard deviations (SD) by sub-groups to illuminate which exposures elevated the risk in each sub-group (Figure \ref{fig_lrp_flow} row 4). An indication of synergism is when the risk contributions - had all other values been zero - are lower than the risk contribution given the indivisual's set of exposures, which can also be added to the table. Further formal investigation of synergism should be conducted (see formulas by VanderWeele[@vanderweele2015]).

```{r, echo = FALSE, eval=FALSE}
# Piotr, there are inconsitent results from using weights in hclust!
# (it worked on our example by accident but not on the iris data)
  data(iris)
  iris <- round(iris[,1:4])
  groups =3
  library(fastcluster)
  p <- plyr::count(iris)
  pfreq <- p$freq
  p <- p[,-ncol(p)]
  phc <- hclust(dist(p,method = "manhattan"),method = "ward.D", members=pfreq)
  clus_aggre <- cutree(phc, groups) # Gruppering paa aggregeret data
  id <- 1:nrow(iris)
  temp <- merge(cbind(id,iris),cbind(p,clus_aggre))
  clus_new <- temp$clus_aggre[order(temp$id)]

  hc <- hclust(dist(iris,method = "manhattan"), method="ward.D") #ward.D
  clus <- cutree(hc, groups) # Gruppering paa al data
  table(clus,clus_new) # Not consistent
  View(cbind(iris,clus,clus_new))
```

### R package
We provide the R package 'CoOL' for phase 2, which can be installed in R using the commands:

> if(!require("devtools")) install.packages("devtools")
>
> devtools::install_github('ekstroem/SRCL')

**Attention: The R package still uses the previous name, SRCL. If we go for the updated name, we will update the R package.**

## Phase 3: Hypothesis development and testing
The results of phase 2 may provide us with empirical information about different sets of exposures  in the study population, which may have led to the outcome. This evidence should be interpreted in the light of the causal model that was specified in phase 1. This may lead to new hypotheses about multifactorial etiology, which may be denoted in a DAG as done by VanderWeele.[@VanderWeele2007] The empirical evidence from phase 2 highlights the outcome prevalence and risk distribution across population sub-groups and may direct attention towards groups with a potentially larger public health impact. It may be that unmeasured confounding influenced our results based on our prior causal assumptions, which suggests that further work needs to be conducted to validate the findings and to understand how risk may be mitigated for the sub-groups. The major gain by using the CoOL approach compared to many other machine learning approaches is that the sub-groups can be defined by specific combinations of exposures that are easily communicated rather than by a black box algorithm.

To verify these findings, the natural next step is validating the findings in external population (either temporal validation or more desirable, external validation). If replicable, the researchers need to provide evidence that the replicated finding is causal (and not due to similar bias structures) for example using various triangulation approaches with orthogonal bias structures [@lawlor2016] including e.g. studies outside the epidemiological field such as animal studies. Eventually, and if possible, the hypotheses needs to be tested using some randomized set-up e.g. natural experiments, Mendelian randomization, or RCTs.


# A CoOL demonstration
Let us consider a fictive population of 40 000 individuals. The data is generated according to Figure \ref{fig_motivating}A. The code generating the data and allowing for reproduction of our results is available in the Supplementary material \ref{datagen} and the R package. Simulating a real-life setting, we aim at identifying the different exposures which may have led to the outcome. Given the way data is generated, we should ideally be able to identify the following exposures which together caused the outcome: **Cause combination 1** with: Not *physically active* and *low-density lipoprotein (LDL)* and *night shift*, and **Cause combination 2** with: *Mutation X* and *air pollution*. As a result, the example data includes synergism; no cause acts alone, but depends on other measured and unmeasured exposures to become sufficient to cause disease Y. Low socio-economic status (SES), genes and living area act through mediators. U denotes an unmeasured exposure. While this example is simple compared with real life data, it serves the purpose of demonstrating the relation between a known data generating process and the results of the CoOL approach.

![A) Data generating process. Each arrow between factors shows the causal direction and the risk difference the exposure affects the outcome with. B) Directed Acyclic Graph on prior knowledge for the CoOL demonstration. \label{fig_motivating}](Figures/Combined motivating.jpg){width=100%}

### Conventional approach 1: Marginal effects of single exposures from a causally adjusted model

One conventional approach to assess the importance of multiple factors for a given disease is to calculate their association to the outcome adjusted for potential confounders of each variable given the assumed causal structure. For example, to suggest important environmental risks, Patel et al. used a similar multiple-adjusted model, a decision algorithm on chance findings, and a validation data set to justify their results.[@patel2012] Below are the adjusted risk difference estimates according to DAG-rules for Figure 1B. This model does not illuminate that Not *physically active*, *low-density lipoprotein (LDL)* and *Night shift* act together as well as *Mutation X* and *Air pollution* act together. Also, estimating effect estimates does not tell us about the public health impact unless we combine these estimates with estimates of the proportion of the population exposed.


```{r linear effect, echo=FALSE}
library(knitr)
library(SRCL)
#set.seed(1)
# data <- SRCL_0_synthetic_data(40000)
# data$Physically_active <- 1-data$Physically_active
# names(data)[2] <- "Not_physically_active"
load("Motivating.RData")

in_fun <- function(fit) {paste0(format(round(summary(fit)$coefficients[2,1]*100,1),nsmall=1)," (",format(round(confint(fit)[2,1]*100,1),nsmall=1)," to ",format(round(confint(fit)[2,2]*100,1),nsmall=1),")")}

tab <- data.frame(1)
for (i in 2:7) {
  tab[i-1,1] <- in_fun(lm(Y~.,data=data[,c(1,i)]))
}


tab[1,2] <- in_fun(lm(Y~Not_physically_active + Low_SES,data=data)) 
tab[2,2] <- in_fun(lm(Y~Low_SES,data=data))
tab[3,2] <- in_fun(lm(Y~Mutation_X+LDL,data=data))
tab[4,2] <- in_fun(lm(Y~LDL+Mutation_X,data=data))
tab[5,2] <- in_fun(lm(Y~Night_shifts + Low_SES+Air_pollution,data=data))
tab[6,2] <- in_fun(lm(Y~Air_pollution+Night_shifts+Low_SES,data=data))

colnames(tab) <- c("Additional cases per 100 persons (95% CI)","Additional cases per 100 persons, adjusted (95% CI)")
var_names <- c("Not physically active$^a$","Low SES","Mutation X$^b$", "LDL$^c$","Night shifts$^d$","Air pollution$^e$")
rownames(tab) <- var_names
tab <- tab[,2]
kable(cbind(var_names,tab), caption = c("Single effects from causally adjusted model"),col.names= c("Exposures","Additional cases per 100 persons (95% CI)"))

```

*$^a$adjusted for low SES, $^b$adjusted for LDL, $^c$adjusted for Mutation X, $^d$adjusted for low SES and air pollution,  $^e$adjusted for night shifts and low SES*


### Conventional approach 2: Classify-analyze


```{r basic clustering, echo=FALSE}
#library(knitr)
load("Motivating.RData")

# library(fastcluster)
# groups  <- cutree(hclust(dist(data[,2:7],"euclidean"),"ward.D"),5)
# groups <- as.numeric(groups)
# save(data,groups,file="Motivating.RData")
library(readr)
mydata <- summary(data[groups==1,1:7])
tab <- parse_number(mydata[4,])
mydata <- summary(data[groups==2,1:7])
tab <- rbind(tab,parse_number(mydata[4,]))
mydata <- summary(data[groups==3,1:7])
tab <- rbind(tab,parse_number(mydata[4,]))
mydata <- summary(data[groups==4,1:7])
tab <- rbind(tab,parse_number(mydata[4,]))
mydata <- summary(data[groups==5,1:7])
tab <- rbind(tab,parse_number(mydata[4,]))

#names(data)
tab <- t(tab)
tab2 <- rbind(tab[2,],tab[3,],tab[4,],tab[5,],tab[6,],tab[7,],tab[1,])
tab <- tab2
tab <- as.data.frame(tab)
colnames(tab) <- 1:5
var_names <- c("Not_physically active","Low SES","Mutation X", "LDL","Night shifts","Air pollution")
rownames(tab) <- c(var_names,"Risk of disease Y")
tab <- round(tab*100,0)
for (i in 1:nrow(tab)) tab[i,] <- paste0(tab[i,],"%")
colnames(tab) <- paste0(c("Group 1", "Group 2", "Group 3", "Group 4", "Group 5"), paste0(" (",round((table(groups)/length(groups) ) * 100),"%)"))
tab <- rbind(tab[1:6,],"",tab[7,])
rownames(tab)[7] <- "Step 2:"
tab <- rbind("",tab)
rownames(tab)[1] <- "Step 1:"

```

Another frequently used approach for estimating disease risk for a population with multiple exposures is to classify individuals into sub-groups by their exposure distributions and then estimate the risk of the disease by each sub-group. For example, some of the authors of this paper used a multi-dimensional trajectory approach to discover trajectories of childhood adversities (0-15 years) among more than 1 million Danish individuals, and subsequently estimated the mortality rate in each trajectory [@rod2020]. Below, we used hierarchical clustering (Euclidean distances and the Ward method[@murtagh2014]) to identify 5 sub-groups. As demonstrated, the clustering approach separates the exposures with great differences between the groups, e.g. sub-group 3 is defined entirely by exposure to air pollution and the absence of other exposures. This approach, however, does not necessarily identify which most relevant combinations of exposures are associated with elevated risks, because the clustering approach is optimized solely on combinations of exposure information. In this scenario the risks of disease Y are approximately similar across all sub-groups.

```{r}
kable(tab, caption = "Classify-analyze results")
```


## CoOL phase 1
We now domonstrate the CoOL approach on the syhtnetic data generated from Figure \ref{fig_motivating}A. As in a real-life situation, we would base our DAG on existing knowledge on the relation between exposures, we may come up with a DAG like the one presented in Figure \ref{fig_motivating}B. Since DAGs generally do not allow for a notation of interactions, we here leave it as a classical DAG. However, if we had a concrete hypotheses, we may denote it similarly to VanderWeele.[@VanderWeele2007] The researchers' interest is in exploring which different sets of exposures that may have led to the outcome in this study population.

## CoOL phase 2

Our data simulation included relatively rare outcomes with a high degree of uncertainty. As a result, the baseline risk is considerable and risks are far from certain if individuals have any of the cause combinations. Due to the data generating mechanisms, our expectations to data are that 1.8% of the study population are exposed to the cause combination 1: Not *Physically active* and *LDL* and *Night shift*, which increases the risk by 15%. We expect that this combination of exposures contribute to 4.9% of the cases. The cause combination 2: *Mutation X* and *Air pollution* has a prevalence of 1.2% in the study population and increases the risk of the disease by 10%. This combination of exposures contribute to 2.3% of the cases. See the theoretical calculations in the supplementary material \ref{expectations}. Based on domain expertise on the causal relation between physical activity and health, we recode physically active so that not-physically active is coded 1 and and physically active is coded 0. We show the true excess fractions of the two combinations of exposures for one simulation in the bottom of Figure \ref{fig_results}F under "SG1" and "SG2".

Using stochastic gradient decent, we fitted a monotonistic neural network with 5 syngergism-functions and with 100 epochs of patience each with a learning rate of $10^{-4}$, $10^{-5}$, and $10^{-6}$. 5 synergism-functions are arbitrary, and the researchers should confirm that adding more hidden states do not change the results. We expect that the model complexity can be saturated. The trained model structure and its accuracy (as the area under the receiver operating characteristic [AUROC]) for one analysis are shown in Figure \ref{fig_results} (a tutorial with the R code to replicate our results using the CoOL package is included in the Supplementary material \ref{tutorial}). Notice that the accuracy measured by AUROC is low (0.54; where 0.5 indicates random prediction) (Figure \ref{fig_results}C).

The dendrogram suggests 3 groups (Figure \ref{fig_results}D). The results of clustering the risk contribution matrix to 3 sub-groups are shown in the plot visualising sub-groups' prevalences and risks (Figure \ref{fig_results}E) as well as in the table with the mean risk contributions by sub-group (Figure \ref{fig_results}F). First, we find that that the baseline risk is estimated to the expected 0.05 (as illustrated by the lower horizontal line in Figure \ref{fig_results}E and shown in Figure \ref{fig_results}F under 'baseline_risk'). We also find that the correct sets of combination of exposures are identified (Sub-group 2 with: Not *Physically active* and *LDL* and *Night shift*. Sub-group 3 with: *Mutation X* and *Air pollution*) as shown in Figure \ref{fig_results}F by the prominent risk contributions for each exposure in sub-group 2 and sub-group 3. The model-based predicted risk, as shown under "risk" in the left column in Figure \ref{fig_results}F is close to the expected risk from the data generating process, but also the measured risk in each cluster, and the "obs risk" being the risk in the assigned sub-group. Not only are the component causes identified, but also the proportion of cases attributed to these causes, as seen under "excess" in Figure \ref{fig_results}F, are close to the expected proportion (Supplementary material \ref{expectations}). We also calculate, in brackets, what would be the risk contribution had all other values been zero (Supplementary material \ref{calculations}). High risk contributions, compared with these values, indicate synergism. In a real world dataset, these findings should be confirmed in a hold out test dataset before used for hypotheses development.

When repeating the simulations 100 times, we can identify both combinations of component causes in 99 out of 100 simulations (Supplementary material \ref{repeated} and  [link to online zip file](https://drive.google.com/file/d/1dHXyuZ3WlHY4hc3YoALzIzi_2oSJDiX0/view?usp=sharing)). However, these results indicate that the true proportion of cases is consistently underestimated, which is likely due to limited sample sizes and noise signals. If we add random variables (1 to 25), the estimates are slightly weakened, but the cause combinations are generally consistently identified ([link to online zip file](https://drive.google.com/file/d/1n-Lj9NKKW3eD6TNWjYTjiTTh79e4Lc9K/view?usp=sharing)). We also investigated the effect of changing the number of synergism-functions, which indicate that the number should be equal or larger than the number of combination of exposures causing the outcome as mentioned in section \ref{fitting} ([link to online zip file](https://drive.google.com/file/d/1q5xXx99XpZ2j3bIz4kscGFTL--LPgM6-/view?usp=sharing)).

![A) The performance plot shows the decline in mean squared error by each epoch of training. B) The model plot visualise the parameters of the trained monotonistic neural network. C) The accuracy plot shows the area under the receiver operating characteristic. D) The dendrogram shows the similarity of risk contributions by individuals. E) The prevalence and mean risk of sub-groups plot gives an indication of which sub-group carries the greatest disease burden. F) The table of mean risk contributions by sub-group indicates which exposures elevate the risk for the specific groups. In the first column in the table; n is the number of individuals in the sub-group, e is the number of events in the sub-group, 'prev' is the prevalence of the sub-group, 'risk' is the estimated risk for the sub-group, 'excess' is the estimated proportion of cases above baseline in this sub-group, and 'obs risk' gives the 95% confidence interval for the risk of being a case in the subgroup estimated from the actual proportion of cases in the sub-group. By cross tabulation, the risk in each of the two causes are shown with SG1 and SG2 for this data simulation.  \label{fig_results}](Figures/SCL.png){width=100%}

## CoOL phase 3
Based phase 1 and 2, we can revisit our DAG to assist our understanding of the various events which may have caused the health outcome, and thus where interventions may have the greatest impact. Our observations suggest that the cause combination 1: Not *physically active* and *LDL* and *Night shift* together contributes to the largest share of cases. This may lead to a hypothesis of multidimentional stress on the immune system. A biological rationale would help scope further studies. Existing data could further test the hypothesis e.g. using a nested cohort study with baseline blood samples for immune cell counts, cholesterol measurements, and an elaborate questionnaire or re-analyses of data from an exercise intervention on whether night shift workers experienced a greater benefit than day time workers. If the hypotheses is supported, it may then be tested using a randomised design.

# Discussion
We have demonstrated the CoOL approach, which investigates the various events which may have led to a health outcome within a pre-specified causal structure. New learnings can be formulated as hypotheses and do not rely on a black box algorithm. The hypotheses can be challenged e.g. using triangulating from various sources of data.


## Limitations
As outlined in the introduction, the task of identifying the causes of an outcome is challenging, and our approach has limitations. With the aim of approximating causal effects, our approach builds on the assumptions of a true causal structure, exchangeability, perfect measurements, positivity, no systematic censoring and the stability assumption, which have all been explained in detail elsewhere.[@hernan2019] In addition, we will highlight some specific limitations to the CoOL approach.

<!--
### Uncertainty and chance findings
In theory, researchers
may wish to fix the deterministic problem of Rothman’s pies by “simply think(ing)
of the components as contributing together to the probability of the effect, rather
than being sufficient for it” [50]. In practice, all epidemiologists can provide is an
approximation of “real” causes via the identification of risk factors.

fra : Causation in Population
Health Informatics
and Data Science 
-->

<!-- ### Different structures could lead to similar results
-->
Co-occurring associations can occur due to five causal structures: Interactions, exposures sharing a common cause (clustered causes), mediation, unmeasured confounding, and by conditioning on a common effect (M-bias). These structures are shown in Figure \ref{fig_causal_structures}, where A and B denotes measured exposures of interest, U denotes an unmeasured cause of A and B, and Y denotes the outcome. *Interactions* are the only of these structures that cause a combined effect, which is different from the sum of the individual effects. When studying non-randomized epidemiological studies, complex combinations of all of these structures can be expected. Researchers will need to assess various potential hypotheses through e.g. triangulation to determine each hypothesis' explanatory capacity. If the researchers' aim is not to uncover etiology, CoOL can also be used for the identification of high risk groups by key identifying factors, which can easily be communicated and used independently of the model in opposition to black box algorithms.

![Five types of causal structures causing co-occurring associations. \label{fig_causal_structures}](Figures/figures.jpg){width=100%}



<!--
###Syndemics


### diskuter reference class problem! Læs artiklen Personalized evidence based medicine:
-->

<!--### Monotonicity
-->
The monotonicity assumption - that all causes have either no effect or positive effects on the outcome through all their potential pathways - is a debatable assumption, when dealing with interactions, as antagonistic effects are of interest to epidemiologists. The monotonicity assumption limits the scope of the CoOL approach to discovering exposures which positively contributed to the sub-groups' risks. The assumption, however, allows us to estimate causal effects compared to a defined reference group. It should be noted that there is a risk of introducing collider bias by including and assessing multiple exposures [@VanderWeele2007; @vanderweele2017]. The use of close to zero risk contributions prevents the clustering approach from introducing collider bias since data would otherwise take a compositional structure introducing distribution dependencies for one sub-group based on the distributions of other sub-groups. The intuition behind this is that all effects are either positive or zero, thus conditioning on a common effect may introduce negative associations between unrelated exposures - as no negative effects are decomposed, then no sub-group can be defined by the collider bias.

<!--### Proximal and distal causes
-->
Rose described chains of causes by separating causes into distal and proximal causes.[@rose1992] Proximal causes, e.g. infectious agents, dietary deficiencies, smoking, toxic exposures and allergens, are close to the outcome in the causal chain, and distal causes, e.g social and economical positions, as the causes of causes and thus are distal to the outcome in the causal chain. Such frameworks have been further expanded in the exposome literature [@wild2012]. When considering multiple causes, uncovering the causal structure and the total effect of causes becomes challenging since the effect of one exposure may be mediated through others. Thus by having one combined model, total effects of all exposures cannot be estimated - only the direct effects [@vanderweele2017]. The researcher will need to consider which potential causes to include. There may be a reason for not including proximal non-manipulative causes in the analysis but distal non-manipulative causes may be of great value - not as a target of an intervention but because they may hold information about high risk strata and by including them may reduce confounding. Furthermore, insight provided by distal causes may enable us to formulate public health interventions that rather than aiming to eliminate the exposure(s) will attempt to mitigate its effects. Confounding is usually defined as a common cause of the exposure and the outcome [@hernan2019], thus *confounders* are of our interest as they are causes of the outcome. Non-manipulative factors such as calendar time or seasonality may also affect exposures and outcomes, and thus, in some situations, we may want to control for e.g. time, which can be done by including the confounder as a risk contributor. Attribution of risk contribution to confounders, such as time, indicate a temporal change of unobserved causes. Alternatively, we may want to control for a constant effect of a confounder as if all individuals were exposed to its reference level (e.g. calendar time). This requires the assumption that the confounder does not interact with any of the exposures of interest. The latter approach may allow us to focus on the exposures of interest, and not let the confounder be a driving factor for the cluster analysis. In this case, we suggest the procedure explained in the Supplementary material \ref{confounder}, which the CoOL R package also facilitates.

The monotonistic single hidden-layer neural network model does not prevent estimating a risk above 1, but this would be unlikely, as risks of morbidity and mortality even for high risk groups in general are far below 1 and because predicted risks are only calculated within the data space available. However, the researcher should check that probabilities are not estimated above 1 (The provided R package warns if this happens).

The use of a test dataset does not seem to assist in deciding on the optimal number of training epochs possibly due to the constrains due to the monotonicity assumption, but more work should allocated to investigating this. For now, we suggest manually confirm the findings in a test data set before developing new hypotheses.

We expect that this approach requires very large data sets since elevated risks in small sub-groups can sometimes be a difference of few cases. Further, the validation processes by replicating the findings in a test data set and by developing hypotheses for further testing in new data with other study designs will safeguard disseminating spurious findings due to type 1 errors from an overfitted model.

The version of CoOL we have presented deals with binary exposures and outcomes. The approach can be extended to continuous outcomes, where the value 0 has a meaningful interpretation. An example could be the use of *loss of disease-free years*, which is continuous, 0 has a meaningful interpretation, and the mean expected values will be the mean loss of disease-free years in the sub-group. However, if measuring BMI, zero would not take a meaningful interpretation. Multiple other extensions of CoOL may be possible (e.g. ways to incorporate time), and we encourage others to explore these. The best presentation of the results will depend on the aim and extensions of the CoOL approach.

## Comparison with other approaches

Our CoOL demonstration showed how some commonly applied approaches in epidemiology, such as causally adjusted models and classify-analyze approaches, both fails to identify the various exposures which may cause an outcome. Many epidemiologists are also familiar with latent class analysis, which attempt to model latent classes causing the exposure distributions. This is a different aim than ours (Figure \ref{fig_models}A), as we are conceptually interested in which different combinations of exposures that become sufficient to cause the outcome. Common use of latent class analyses for morbidity and mortality can be categorized as classify-analyze approach, but one extended version of latent class analysis simultaneously fit latent classes with a distal outcomes [@lanza2013]. However, besides the conceptual difference, there are important drawbacks of this approach if it was to be used to identify synergisms since common exposures will be presented for all classes even if they are not causal. Further, conditionality may be introduced so that if one group is defined by a high prevalence of an exposure, then other groups will be defined by a low prevalence of the exposure even when it is has no causal effect for the other sub-groups.

The CoOL approach relies on LRP, which has previously been successfully demonstrated in fields other than epidemiology, such as image, text and biological data classification [@Samek2016; @Arras2017; @Sturm2016]. LRP has also been used on health records to explain clinical decisions on therapy assignment [@Yang2018] but in this case neither a baseline risk was estimated nor was there interest in identifying sub-groups. Alternative methods to decompose neural network predictions into risk contributions (the original and general term is 'relevances') were proposed recently, such as DeepLIFT [@shrikumar2019] or Integrated Gradients [@sundararajan2017]. However only LRP and its Deep Taylor Decomposition variant fit our assumption of a monotonistic neural network, and allow a seamless interpretation of relevances as risk contributions in our causal inference setup.[@Montavon2017] We did not want to consider perturbation-based explanation techniques such as LIME [@ribeiro2016], since our question of interest is causes of an outcome such as "*Given a particular health outcome, what are the various sets of events which might have been its causes?*" rather than effects of causes such as "*What would have occurred if a particular factor were intervened upon and thus set to a different level than it in fact was?*" - aspects which has been previously discussed both in the causal inference literature [@vanderweele2006] and in the literature on LRP [@Montavon2018]. Furthermore, perturbation-based methods produce localized explanations which may not be generalize to global causal pathways [@Samek2016; @zeiler2013; @fong2017].

## Conclusion
We have demonstrated a sequence of procedures with the aim of learning about causes of a health outcome. The procedures are based on prior knowledge of the causal structure, the analytical approach enabled by the flexibility of a monotonistic neural network, the LRP explanation technique for decomposing risk contributions and clustering (the R package "CoOL" allows epidemiologists to implement this), and, finally, hypothesis development and testing using classical methods. These are steps towards transparency allowing others to replicate hypothesized causal findings from machine learning models in health science, which is increasingly warranted [@beam2020; @holzinger2019]. We hope this approach will encourage epidemiologists to study the distribution of causes of an outcome in order to eventually develop more effective, targeted, and informed public health interventions.

### Acknowledgment
The authors would like to thank the colleagues at Section of Epidemiology, Department of Public Health, University of Copenhagen for valuable comments and suggestions on the idea throughout the development. <!-- Tue Kjærgaard Nielsen for assistance with dendrogram. Rasmus Wibæk Christensen and ?Stine Byberg? for commenting on the manuscript. -->

### Funding
AR was supported by an international postdoc grant by the Independent Research Fund Denmark (9034-00006B). PD was supported by a research grant from the Danish Diabetes Academy funded by the Novo Nordisk Foundation
<!--
### Author contributions



### Author contribution


### Acknowledgement
-->


\newpage


# Supplementary materials


## Initial values, derivatives, and learning rates \label{derivatives}

The predicted risk, $P(Y|X^+)$ is here denoted $O$, the true outcome is denoted $Y$, the error is estimated as $\frac{(O-Y)^2}{2}$ and denoted $E$, the value taken by each of the hidden synergism-functions $S_j^+()$ activation functions are denoted $S_j$, the input value to $S_j^+()$ activation function values are denoted $s_j$, the parameters from the exposures to the synerg are denoted $\beta_{i,j}^+$, the intercepts for the hidden $S_j^+()$ activation functions are denoted $-\alpha_j^+$, the baseline risk is denoted $R^+_{baseline}$, and the exposures are denoted $X_i^+$.

```{r}
values <- c("abs(0 (0.01))","-abs(0 (0.01))","abs(0 (0.01))")
values <- (data.frame(values))
rownames(values) <-  c("$\\beta_{i,j}^+$","$-\\alpha_{j}^+$","$R^+_{baseline}$")
values$Update <- c("$\\frac{\\delta E}{\\delta \\beta_{i,j}^+} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta S_j}\\cdot\\frac{\\delta S_j}{\\delta s_j}\\cdot\\frac{\\delta s_j}{\\delta \\beta_{ij}}$",
                      "$\\frac{\\delta E}{\\delta -\\alpha_j^+} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta S_j}\\cdot\\frac{\\delta S_j}{\\delta s_j}\\cdot1$",
                      "$\\frac{\\delta E}{\\delta R^{b^+}} = \\frac{\\delta E}{\\delta O} \\cdot 1$
                   ")
values$lr <- c("learning rate","learning rate","learning rate / 10")
values$c <- c("$\\ge$ 0","$\\le$ 0","$\\ge$ 0")
colnames(values) <- c("Initial values (SD)","Derivative","Learning rate","Constrains")
kable(values)


# values <- c("abs(0 (0.01))","-abs(0 (0.01))","abs(1 (0))","abs(0 (0.01))")
# values <- (data.frame(values))
# rownames(values) <-  c("$w_{i,j}$","$b_{j}$","$w_{j,k}$","$R^{b^+}$")
# values$Update <- c("$\\frac{\\delta E}{\\delta w_{ij}} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta H_j}\\cdot\\frac{\\delta H_j}{\\delta h_j}\\cdot\\frac{\\delta h_j}{\\delta w_{ij}}$",
#                       "$\\frac{\\delta E}{\\delta b_j} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta H_j}\\cdot\\frac{\\delta H_j}{\\delta h_j}\\cdot1$",
#                    "$\\frac{\\delta E}{\\delta w_{j,k}} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta w_{j,k}}$",
#                       "$\\frac{\\delta E}{\\delta R^{b^+}} = \\frac{\\delta E}{\\delta O}\\cdot1$
#                    ")
# values$lr <- c("learning rate $\\cdot$ 10","learning rate","learning rate","learning rate / 10")
# values$c <- c("$\\ge$ 0","$\\le$ 0","$\\ge$ 0","$\\ge$ 0")
# colnames(values) <- c("Initial values (SD)","Derivative","Learning rate","Constrains")
# kable(values)

#\frac{\delta O}{\delta w_{j,k}} = H_j,

```

Where: $\frac{\delta E}{\delta O} = O - Y, \frac{\delta O}{\delta S_{j}} = \beta_{j,k}, \frac{\delta S_j}{\delta s_j} = 1$ if $S_j$ > 0 otherwise 0, $\frac{\delta s_j}{\delta \beta_{i,j}}=X_i^+$

## Calculating the risk based on the sum of individual effects \label{calculations}

If we denote the combined risk as $P(Y=1|X^+)$, the risk based on the sum of the individual effects can be estimated as:

$$R^+_{baseline}+\sum_i{\big(P(Y=1|X^+_i=x_i^+,X^+_{!i}=0})-R^+_{baseline}\big)$$

Where $R^+_{baseline}$ is the baseline risk, $x_i^+$ is the actual value taken by $X_i^+$, and $!i$ denotes all but $i$.

\newpage

## Control for a constant effect of a confounder as if all individuals were exposed to its reference level \label{confounder}
To control for a constant effect of a confounder as if all individuals were exposed to its reference level (e.g. calendar time), we need to assume it does not interact with any of the exposures. This may allow us to focus on the exposures of interest for the cluster analysis as had all individuals had the same reference level of the confounder. In this case, we connect the confounder to the output layer as in below figure. The CoOL R package also facilitates this approach.

In below figure, $C$ denotes a confounder. Given below causal structure, the average causal effect in the total population for being exposed to combination $z$ of the exposures compared with the baseline risk is thus given by $P(Y_{X_z,C=0})-P(Y_{baseline}) = P(Y=1|X^+=z,C^+=0) - P(Y=1|X^+=0,C^+=0)$.

![](Figures/combined_models_confounder.jpg){width=100%}

This changes the denotation of the fitted monotonistic neural network to:

$$P(Y=1|X^+,C^+)=\sum_{j}\Big(S_j^+\big(\sum_{i}(X_i^+ \cdot \beta_{ij}) -\alpha_j\big)\Big) + c^+C^+ + R^+_{baseline}$$

We then decompose the predicted risk had $C^+$ been its reference of zero, $P(Y=1|X^+,C=0)$ into the reference baseline risk, $R^{b^+}$, and the risk contributions of exposures, $R^X_i$:

$$P(Y=1|X^+,C^+=0)=R^+_{baseline}+\sum_iR^X_i$$

The decomposition of the risk contributions for exposures, $R^X_i$, now takes these 3 steps:

Step 1 - Subtract the baseline risk, $R^{b^+}$: $R^X_k =  P(Y=1|X^+,C^+=0)-R^+_{baseline}$

Step 2 - Decompose to the hidden layer: $R^{X}_j =  \frac{S_j}{\sum_jS_j} R^X_k$

<!--
$$R^X_j =  \frac{H_j e^{w_{j,k}}}{\sum_j(H_j e^{w_{j,k}})} \Big(P(Y=1|X)-f_k(b_k)\Big)$$
-->

*Where $S_j$ is the value taken by each of the $S_j^+()$ functions for the specific individual.*

Step 3 - Hidden layer to exposures: $R^{X}_i = \sum_j \Big(\frac{X_i^+ \cdot \beta_{i,j}}{\sum_i( X_i^+ \cdot \beta_{i,j})}R^X_j\Big)$

This creates a *risk contribution matrix* with row length equal to the number of individuals and column length equal to the number of exposures plus a baseline risk value minus the confounder. The following R code shows an example:

```{r, echo=T,eval=F}
gen_data <- function(n) {
  data <- data.frame(V1 = sample(0:1,n,replace = T))
  for (i in 1:15) {data[,i] <- sample(0:1,n,replace = TRUE, prob = c(0.7,0.3))}
  C = as.numeric(sample(0:1,n,replace=TRUE,prob = c(0.5,0.5)))
  for (i in 1:nrow(data)) {if (C[i]==1 & sample(0:1,1,prob = c(0.7,0.3))==1) {
    data[i,2] <- 1}}
  for (i in 1:nrow(data)) {if (C[i]==1 & sample(0:1,1,prob = c(0.8,0.2))==1) {
    data[i,12] <- 1}}
  data$Y <-  sample(0:1,n,replace = T, prob = c(0.95,0.05))
  for (i in 1:nrow(data)) {if (C[i]==1 & sample(0:1,1,prob = c(0.8,0.2))==1) {
    data$Y[i] <- 1}}
  for (i in 1:nrow(data)) {if (data[i,10]==1 & sample(0:1,1,prob = c(0.95,0.05))==1) {
    data$Y[i]<- 1}}
  for(i in 1:ncol(data)) {data[,i] <- as.numeric(data[,i])}
  data$C <- C
  data <- data[,c(16,1:15,17)]
  return(data)
}
# Make sure the devtools package is installed
devtools::install_github('ekstroem/SRCL')
library(SRCL)
data <- gen_data(10000)
c <- data$C
data <- data[,-ncol(data)]
# Code data monotonisticly
lm(Y~.,data)
recode <- lm(Y~.,data)$coefficients<0
for (i in 2:ncol(data)) {
  if(recode[i]==TRUE) colnames(data)[i] <- paste0("Not_",colnames(data)[i])
  if(recode[i]==TRUE) data[,i] = 1 - data[,i]}
summary(lm(Y~.,data))
exposure_data <- data[,-1]
outcome_data <- data[,1]
# Model fit without the confounder
model <- SRCL_initiate_neural_network(inputs=ncol(exposure_data),hidden=5)
for (lr_set in c(0.01,0.001,0.0001,0.00001)) {
  model <- SRCL_train_neural_network(exposure_data,outcome_data,model,
          lr = lr_set, epochs=1000,patience = 10,plot_and_evaluation_frequency = 50)}
# Model visualisation
SRCL_plot_neural_network(model,names(exposure_data),5)
# Should only be influenced by V10...
# Model fit with the confounder
model <- SRCL_initiate_neural_network(inputs=ncol(exposure_data),hidden=5,confounder=TRUE)
for (lr_set in c(0.01,0.001,0.0001,0.00001)) {
  model <- SRCL_train_neural_network_with_confounder(exposure_data,outcome_data,c,model,
          lr = lr_set, epochs=1000,patience = 10,plot_and_evaluation_frequency = 50)
}
SRCL_plot_neural_network(model,names(exposure_data),5)
# Only information comes from V10 now.

```


\newpage

##  Data generation for the CoOL demonstration \label{datagen}

```{r,echo=T,eval=F}
### The data generating process
data_gen<- function(n) {
  Genes = sample(1:0,n,prob=c(0.05,0.95),replace=TRUE)
  Living_area = sample(1:0,n,prob=c(0.2,0.8),replace=TRUE)
  Low_SES = sample(1:0,n,prob=c(0.2,0.8),replace=TRUE)
  Physically_active = sample(1:0,n,prob=c(0.8,0.2),replace=TRUE)
  for (i in 1:n) {if (Low_SES[i] == 1 & sample(1:0,1,prob=c(.2,.8))) Physically_active[i] <- 0}  
  Mutation_X = rep(0,n)
  for (i in 1:n) {if (Genes[i] == 1 & sample(1:0,1,prob=c(.95,.05))) Mutation_X[i] <- 1}  
  LDL = sample(1:0,n,prob=c(0.3,0.7),replace=TRUE)
  for (i in 1:n) {if (Genes[i] == 1 & sample(1:0,1,prob=c(.15,.85))) LDL[i] <- 1 }
  Night_shifts = sample(1:0, n, prob = c(0.2, 0.8), replace = TRUE)
  for (i in 1:n) {
    if (Living_area[i] == 1 & sample(1:0, 1, prob = c(0.1,0.9))) Night_shifts[i] <- 1
    if (Low_SES[i] == 1 & sample(1:0, 1, prob = c(0.1, 0.9))) Night_shifts[i] <- 1 }
  Air_pollution = sample(1:0,n,prob=c(0.2,0.8),replace=TRUE)
  for (i in 1:n) {if (Living_area[i] == 1 & sample(1:0,1,prob=c(.3,.7)) ) 
    Air_pollution[i] <- 1}  
  Y <-  sample(1:0,n,prob=c(0.05,0.95),replace = TRUE)
  for (i in 1:n) {
    if (Physically_active[i] == 0 & LDL[i] == 1 & Night_shifts[i] == 1 &
        sample(1:0,1,prob=c(.15,0.85)) ) {Y[i] <- 1 }
    if (Mutation_X[i] == 1 & Air_pollution[i] == 1 & sample(1:0,1,prob=c(.1,0.9))) {
      Y[i] <- 1}}
  C = rep(0,n)  
  data <- data.frame(Y,Physically_active,Low_SES,Mutation_X,LDL,Night_shifts,Air_pollution,C)
  for (i in 1:ncol(data))   data[,i] <- as.numeric(data[,i])
  return(data)
}
### Generates a population of 40000
  data <- data_gen(40000)
```



## Theoretical expectations to the CoOL demonstration \label{expectations}


```{r,echo=F}
# Data simulation
P_Y_U = 0.05
P_Y_MA = 0.1
P_MA =(0.05*0.95)*(0.2*0.3+0.2)
P_Y_SLN = 0.15
P_SLN = (1-(0.8-0.2*0.2))*(0.3+0.05*0.15)*(0.2+0.2*0.1+0.2*0.1)
P_Y = (1- (1-P_Y_U) * (1-P_Y_MA*P_MA) * (1-P_Y_SLN * P_SLN))
```

$P(Y|U)=0.05$

$P(Y|MutationX,Airpollution)=0.1$

$P(MutationX,Airpollution)=(0.05\cdot0.95)\cdot(0.2\cdot0.3+0.2)=$ `r P_MA`

$P(Y|NotPhysicallyActive,LDL,NightShift)=0.15$

$P(NotPhysicallyActive,LDL,NightShift)=(1-(0.8-0.2\cdot0.2))\cdot(0.3+0.05\cdot0.15)\cdot(0.2+0.2\cdot0.1+0.2\cdot0.1)=$ `r P_SLN`

$P(Y) =(1- (1 - P(Y|U)) \cdot  (1 - P(Y|MutationX,Airpollution)\cdot P(MutationX,Airpollution)) \cdot (1 - P(Y|NotPhysicallyActive,LDL,NightShift)\cdot P(NotPhysicallyActive,LDL,NightShift)) )=$ `r P_Y`

$\frac{P(Y|MutationX,Airpollution)\cdot P(MutationX,Airpollution)}{P(Y)}=$ `r P_Y_MA*P_MA / P_Y `

$\frac{P(Y| NotPhysicallyActive,LDL,Night Shift) \cdot P(NotPhysicallyActive,LDL,Night Shift)}{P(Y)}=$ `r P_Y_SLN*P_SLN/P_Y`


\newpage

##  Tutorial for analysing the CoOL demonstration \label{tutorial}

We follow the line of thinking in the CoOL demonstration. At phase two, we estimate sub-groups with similar risk contributions using the following code.

First we install and load the CoOL package.
```{r,echo=T,eval=F}
# Make sure the devtools package is installed
devtools::install_github('ekstroem/SRCL')
library(SRCL)
```

We generate data for the CoOL demonstration.

```{r,echo=T,eval=F}
# Data simulation
set.seed(123456789)
data <- SRCL_0_synthetic_data(40000)
```
We recode data monotonistically. Here we automate the process, but these decisions will be better guided by domain expertise.
```{r,echo=T,eval=F}
# Code data monotonisticly
lm(Y~.,data)
  # We choose to recode Physically_active to not_Physically_active
  data$Physically_active <- 1 - data$Physically_active
  names(data)[2] <- "Not_physically_active"
coefficients(summary(lm(Y~.,data)))
```

```{r}
library(SRCL)
data <- SRCL_0_synthetic_data(40000)
# We choose to recode Physically_active to not_Physically_active
data$Physically_active <- 1 - data$Physically_active
names(data)[2] <- "Not_physically_active"
coefficients(summary(lm(Y~.,data)))
```

We split data into one data set with exposures and one data set with the outcomes. Here $Y$ was at the first column.

```{r,echo=T,eval=F}
exposure_data <- data[,-1]
outcome_data <- data[,1]
```

We first initiate the monotonistic neural network with the number of exposures and potential hidden synergistic component causes. We then train the monotonistic neural network with different learning rates (lr) each with a patience of 100 epochs. Model training can be time consuming even with our optimized fitting function. Separating the initiation and training of the monotonistic neural network allows one to continue training the model at later time points.

```{r,echo=T,eval=F}
# Model fit
model <- SRCL_1_initiate_neural_network(inputs=ncol(exposure_data),hidden=5)
for (lr_set in c(0.0001,0.00001,0.000001)) {
  model <- SRCL_2_train_neural_network(exposure_data,outcome_data,model,
      lr = lr_set, epochs=1000,patience = 100,plot_and_evaluation_frequency = 50)
}
```

When the model is trained, we present the model training performance, an illustration of the network and a ROC plot as in Figure \ref{fig_results}.
```{r,echo=T,eval=F}
# Performance
par(mar=c(5,5,2,0))
plot(model$train_performance, type='l',yaxs='i', ylab="Mean squared error",
     xlab="Epochs",main="Performance")

# Model visualisation
par(mar=c(0,0,0,0))
SRCL_3_plot_neural_network(model,names(exposure_data),5)

# AUC
library(pROC)
par(mar=c(5,5,2,0))
pred <- SRCL_4_predict_risks(exposure_data,model)
plot(roc(outcome_data,pred),print.auc=TRUE,main="Accuracy")
```

We then decompose the risks into risk contributions for each exposure and a baseline.
```{r,echo=T,eval=F}
# Risk contributions
r_c <- SRCL_5_layerwise_relevance_propagation(exposure_data,model)
```

We show the dendrogram colored for 3 sub-groups as in Figure \ref{fig_results}.
```{r,echo=T,eval=F}
# Clustering
groups =3
colours <- c("grey","dodgerblue","red","orange")
library(fastcluster)
p <- cbind(r_c)
p <- plyr::count(p)
pfreq <- p$freq
p <- p[,-c(ncol(p))]
p_h_c <- hclust(dist(p, method = "manhattan"),method = "ward.D", members=pfreq)
pclus <- cutree(p_h_c, groups)
id <- 1:nrow(r_c)
temp <- merge(cbind(id,r_c),cbind(p,pclus))
clus <- temp$pclus[order(temp$id)]
table(clus)

par(mfrow=c(1,1))
par(mar=c(5,5,5,5))
library(ggtree)
library(ggplot2)
print(ggtree(p_h_c,layout="equal_angle") +
  geom_tippoint(size=sqrt(pfreq)/2, alpha=.2, color=colours[pclus])+
  ggtitle("D) Dendrogram") +
  theme(plot.title = element_text(size = 15, face = "bold")))
```

We generate the plot with the prevalence and mean risks of the sub-groups as in Figure \ref{fig_results}.

```{r,echo=T,eval=F}
par(mar=c(4,5,2,1))
plot(0,0,type='n',xlim=c(0,1),asp=1,ylim=c(0,1),xaxs='i',yaxs='i',
     axes=FALSE,ylab="Risk",xlab="Prevalence",frame.plot=FALSE,
     main="Prevalence and mean risk of sub-groups")
axis(1,seq(0,1,.2));axis(2,seq(0,1,.2))
rect(0,0,1,1)
prev0 = 0; total = 0
for (i in 1:groups) {
  prev <- sum(clus==i)/length(clus)
  risk <- sum(colMeans(as.matrix(r_c[clus==i,])))
  rect(xleft = prev0,ybottom = 0,xright = prev+prev0,ytop = risk, col=colours[i])
  prev0 = prev + prev0
  total = total + risk * prev
}
arrows(x0=0,x1=1,y0=mean(r_c$Baseline_risk),lty=1,length=0)
```

And finally the table with the risk contributions as in Figure \ref{fig_results}.

```{r,echo=T,eval=F}
  st <- 1.5
  d <- data.frame(matrix(NA, nrow=ncol(r_c)))
  for (g in 1:groups) {
    for (i in 1:nrow(d)) {
      d[i,g] <- mean(r_c[clus==g,i])
    }}
  d <- t(d)
  rownames(d) <- paste("Group",1:groups)
  colnames(d) <- names(r_c)
  par(mar=c(0,0,0,0))
  plot(0,0,type='n',xlim=c(-ncol(d)-5,0),ylim=c(-nrow(d)-1,1),axes=F)
  text(c(-ncol(d)):c(-1),0,rev(colnames(d)),srt=25,cex=st)
  text(-ncol(d)-5,0,"F) Mean (SD) risk contributions\nby sub-group",pos=4,cex=st)
  for (i in 1:groups) {
    prev <- sum(clus==i)/length(clus)
    risk <- sum(colMeans(as.matrix(r_c[clus==i,])))
    risk_obs <- mean(outcome_data[clus==i])
    text(-ncol(d)-5,-i,paste0("Sub-group ",i,": ","n=",sum(clus==i),", e=",sum(outcome_data[clus==i]),",\nPrev=",format(round(prev*100,1),nsmall=1),"%, risk=",format(round(risk*100,1),nsmall=1),"%, excess=",
   format(round(prev*(risk-mean(r_c$Baseline_risk))/total*100,1),nsmall=1),
   "%,\nObs risk=",format(round(risk_obs*100,1),nsmall=1),"% (",
   paste0(format(round(prop.test(sum(outcome_data[clus==i]),
   length(t(outcome_data)[clus==i]))$conf.int*100,1),nsmall=1),collapse="-"),
    "%)","\nSG1= ",round(mean(data$Y[data$Air_pollution==1&data$Mutation_X==1])*100,1),"%, ",
    "SG2= ",round(mean(data$Y[data$Not_physically_active==1&data$LDL==1&data$Night_shifts==1])*100,1),"%"
  ),pos=4,col=colours[i])
  }
  m <- max(d)
  for(g in 1:ncol(d)) { for (i in 1:nrow(d)){
    value <- paste0(format(round(as.numeric(d[i,g]),2),nsmall=2),"\n(",
                    format(round(sd(r_c[clus==i,g]),2),nsmall=2),")")
    text(-g,-i,value,col=adjustcolor(colours[i],d[i,g]/m),cex=st*d[i,g]/m)
  }
```
















\newpage

## Repeated simulations \label{repeated}

When running the data generating process and phase 2 for 100 times, we can identify both combinations of component causes 99 out of the 100 simulations. These results, however, indicate that we underestimate the true proportion of cases (Figure \ref{fig_repeated}). Finite sample sizes and noise signals could be two factors, which would cause an underestimation of the true proportion of cases.

![100 repeated simulations showing the estimated fractions due to the two combination of causes. The results indicate that we underestimate the true excess fractions.  \label{fig_repeated}](Figures/Repeated.png){width=80%}

\newpage




<!--

```{r,echo=T,eval=F}
### Pre
  summary(lm(Y~.,data=data))
### Prepare the data set (split into a train and test).
# NB using a test set works poorly as a stopping criteria.
  samples_indexes = 1:nrow(data)
  samples_indexes = sample(1:nrow(data),round(nrow(data)/2))
  X = as.matrix(data[samples_indexes, 2:c(ncol(data)-1)])
  X <- matrix(X,ncol=ncol(X))
  Y = as.integer(data[samples_indexes, 1])
  C = as.matrix(data[samples_indexes, ncol(data)])
  Xt = as.matrix(data[-samples_indexes, 2:c(ncol(data)-1)])
  Xt <- matrix(X,ncol=ncol(X))
  Yt = as.integer(data[-samples_indexes, 1])
  Ct = as.matrix(data[-samples_indexes, ncol(data)])
  
###### training: Sigmoid and then training additive ####
# Training algorithm in C++
    model_c <- train_network(X,Y,C,Xt,Yt,Ct, lr = 0.01,maxepochs=10000, hidden=10, 
                             tolerance_rel = 1000, tolerance_abs = 1000)
    model_c_c <- model_c
    model_c_c[[1]] <- model_c_c[[1]][1:c(nrow(model_c_c[[1]])-ncol(model_c_c[[5]])),]
    model_c_c[[8]] = paste0(names(data)[-c(1,ncol(data))],model_c$flipped[-length(model_c$flipped)])
# Ensure data is coded correctly according to the monotonicity assumption. 
    X_flip <- X
    for(i in 1:length(model_c_c$flipped)) {
      if (model_c_c$flipped[i] == 1) { X_flip[,i] = 1-X_flip[,i]}
    }
    Xt_flip <- Xt
    for(i in 1:length(model_c_c$flipped)) {
      if (model_c_c$flipped[i] == 1) { Xt_flip[,i] = 1-Xt_flip[,i]}
    }
# Additive updating of the model
    model_c$W1[nrow(model_c$W1),] <- abs(model_c$W1[nrow(model_c$W1),])
    model_2 <- transfer_network_additive(X_flip,Y,C,Xt_flip,Yt,Ct, lr = 0.01, maxepochs  = 10000,
                                        W1 = model_c[[1]],B1 = model_c[[2]],W2 = model_c[[3]],
                                        B2 = model_c[[4]],C2 = model_c[[5]])
    model_2_c <- model_2
    model_2_c[[1]] <- model_2[[1]][1:c(nrow(model_2[[1]])-ncol(model_2[[5]])),]
    
# Plot the SCL model
    par(mfrow=c(1,1));network_c(model_2_c,1:10,names = model_c_c[[8]])
# Plot AUROC
    pred <- forward_additive(X_flip,model_c_c)
    library(pROC)
    plot(roc(Y,pred),print.auc=T)
# Calculate the risk contribution matrix
    model_2_c[[8]] <- model_c_c[[8]]
    fit_excess <- excess_plot_relu(X_flip[1:35000,],groups=5,font=10, model_c_c =  model_2_c)
# Plot 1
    excess_plot_exp(fit_excess,baseline = T,font=20,groups = 5)
# Plot 2
    excess_plot_exp(fit_excess,baseline = F,font = 30,groups = 5)

```

\newpage




### The Sufficient Cause model, chance and unknowns
The Sufficient Cause Model was introduced in the epidemiologicla field by @Rothman1986. An example: Some patients could have been diseased due to the combination of cause $A$, $B$ and $C$ whereas others due to $D$, $E$ and the absent of $F$ (denoted $\overline{F}$); That is two different sufficient causes ($ABC$ and $DE\overline{F}$). Such component causes may underlie all diseases if we knew enough about their aetiology [@Rothman1986].The lack of measured component causes, imprecision of data, random processes and the vast numbers of potential component causes suggest there exists un upper limit for our ability to identify common component causes [@Smith2019] and applied studies on the sufficient cause framework will inevitably have unknowns (denoted $U_x$, where $x$ unknowns may exist).


![Sufficient causes](Figures/M_1.png){width=30%}

An important notion is between etiological fractions and excess fractions, where an etiological fraction is one combination of causes and the excess fraction of the proportion of disease that would be prevented had we removed one or more exposures from the etiological fraction [@greenland1988]. The sum of excess fractions will sum to more than 100% when we have interacting component causes. Also removing an etiological fraction by removing one exposure of it is not certain to reduce disease if there are co-occuring sufficient causes. Sufficient causes have been formalised in the causal inference literature and shown in directed acyclic graphs [@VanderWeele2007].

![Sufficient causes shown in a DAG](Figures/M_2.png){width=50%}

Sufficient cause interactions can be estimated formally using the following formula under a monotonicity assumption [@vanderweele2015]. The monotonicity assumption is that the causal effect of the exposure(s) of interest on an outcome is monotonic if every individuals' counterfactual outcome is monotonically increasing (or at least not decreasing) with increase in the exposure as well as in any combination with other exposures [@hernan2019].

$$P(Y|A=1,B=1) - P(Y|A=1,B=0) - P(Y|A=0,B=1) + P(Y|A=0,B=0)$$ 

We can also estimate the proportion of the joint effect due to interaction [@vanderweele2015_2]:

$$\frac{P(Y|A=1,B=1) - P(Y|A=1,B=0) - P(Y|A=0,B=1) + P(Y|A=0,B=0)}{P(Y|A=1,B=1)-P(Y|A=0,B=0)}$$ 



\newpage


### Detailed explanation of the analytical SCL model
- "+" denotes monotinistic effects.
- $b$ denotes a bias term in the neural network.
- $C$ denotes a confounder.
- $f()$ denotes an activation function.
- $\lambda$ denotes a potive valued parameter and the monotonistic rule.
- $SC$ denotes synergistic conponent causes.
- $\varphi$ denotes a normal destribution.
- $w$ denotes a weight in the neural network.
- $Y$ denotes the disease outcome.
- $X_i$ denotes exposures.

Structural equation models under a causal structure have been termed structural causal models [@pearl2016], and they function with additional rules to DAGs in linear systems. We perceive the analytical SCL model as a structural causal model.

The SCL model is inspired by neural network with one hidden layer (a shallow neural network). The model differs from normal neural networks as it allows us to be **forcing positive weights**, adding a **dynamic recoding of exposures**, and **adjusting the ML model for potential confounders**. All exposures and outcomes are - for now – assumed to be binary.

A neural network is composed of $i$ exposures ($X_i$) (input layer), a latent non-linear state (hidden layer) and the outcome, Y (output layer). Each arrow has a weight, $w$. The combination if these weights allows the model to make predictions depending on non-linear relationships between multiple exposures simultaneously. To denote each weight, weights are given two subscripts identifying the node it comes from and the node it goes to. We use $i$ for the input layer, $j$ for the hidden layer, and $k$ for the output layer. Weights from the input layer to the hidden layer are denoted $w_{i,j}$ and from the hidden layer to the output layer are denoted $w_{j,k}$. Thus, a weight that goes from the third exposure to the fifth activation function in the hidden layer is denoted $w_{3,5}$.

We expect that unmeasured component causes cause a proportion of the outcomes, hence in our modelling we aim to identify a baseline risk in the population. This would be the risk among those individuals with the lowest risk of the outcome. This aim forces us to interpret an *intercept* of the model. One way to do so, is to restrict exposures to only increase the risk of the outcome and estimate the risk had all exposures been set to zero. We can **force all weights to be positive** by using $e^w$ instead of $w$ as shown in Figure 3. Importantly, this baseline can be represented among groups with various exposure combinations as long as they share the same baseline risk, thus the reference group is likely much broader than those whose exposures are all set to zero.

Making the restriction that all weights can only be positive makes our initial coding of the direction of exposures important. To ensure that the initial coding of our exposures do not affect the model fit, we add a parameter and a rule to the weights between the input layer and the hidden layer, $w_{i,j}$. This parameter is denoted $\lambda_i$. It follows the rule that **if $\lambda_i$ during the model fit becomes negative, then we recodes the exposure to $1-X_i$ and replaces $\lambda_i$ with the absolute value of $\lambda_i$**. The combined weight between the input layer and the hidden layer are $\lambda_ie^{w_{i,k}}$

**To adjust the ML model for confounding**, we use our knowledge from the causal structure, and if the confounder - i.e. time and seasonality - have a direct effect on the disease outcome, Y, we can allow it to be connected directly to the last activation function in the output layer. Such short cut connections have previously been successfully used for non-causal ML purposes [@he2015].


The machine learning model can be denoted:

$$P(Y=1|X)=f_k\bigg(\sum_{j}\Big(e^{w_{j,k}}f_j\big(\sum_{i}(X_i\lambda_ie^{w_{ij}}) + b_j\big)\Big) + b_k\bigg)$$
Where X represents all exposures. $f_j(z)$ and $f_k(z)$ are the activation function for the hidden layer and output layer.

It is normal to ballance 1:1 cases and non-cases in ML approaches, however, this creates a new representation of the study population where half of the population develops the disease outcome. We recommend to avoid ballancing data sets in order to get the right risk predictions in the study population. Similarly, modifications of the learning rate (e.g. through adaptive learning rates) may be problematic for causal estimations.

We would like the model to be additive, thus if no synergistic effects between exposures exist, their combined effect is the sum of their individual effects. However, our experience is that we can consistently fit the model when we use sigmoid function $\frac{1}{1+e^{-(b + w X)}}$ as activation functions, which are not additive, which we cannot with additive activation functions. To reach an additive model, we first fit the model using sigmoid functions as activation functions, and then further slowly train the model to instead use a modified hard sigmoid function in the output layer, where z = 0 if Z < -2, $\frac{Z+2}{4}$ if Z is betwee -2 and 2, and 1 if Z > 2. The difference between the activation functions can be seen below.

![Activation functions](Figures/sig_to_hsig.png){width=50%}

We suggest running several thousands epochs for both the first and second fit, but the training length depends on the data and the problem.



The model is initiated with the following values (normally distributed with a standard deviation of 0.01). The model training is done using gradient decent (backpropagation). We use the following error function $\frac{(O-Y)^2}{2}$, where $O$ is the estimated predicted risk and $Y$ is the measured outcome.

```{r}
values <- c("0 (0.01)","0 (0.01)","-4 (0.01)","1 (0.01)","-5 (0.01)")
values <- (data.frame(values))
rownames(values) <-  c("$\\lambda_i$","$w_{i,j}$","$b_{j}$","$w_{j,k}$","$b_{k}$")
values$Update <- c("$\\frac{\\delta E}{\\delta \\lambda_i} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta \\epsilon_k}\\cdot\\frac{\\delta \\epsilon_k}{\\delta H_j}\\cdot\\frac{\\delta H_j}{\\delta \\epsilon_j}\\cdot\\frac{\\delta \\epsilon_j}{\\delta \\lambda_i}$",
                   "$\\frac{\\delta E}{\\delta w_{ij}} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta \\epsilon_k}\\cdot\\frac{\\delta \\epsilon_k}{\\delta H_j}\\cdot\\frac{\\delta H_j}{\\delta \\epsilon_j}\\cdot\\frac{\\delta \\epsilon_j}{\\delta w_{ij}}$",
                      "$\\frac{\\delta E}{\\delta b_j} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta \\epsilon_k}\\cdot\\frac{\\delta \\epsilon_k}{\\delta H_j}\\cdot\\frac{\\delta H_j}{\\delta \\epsilon_j}\\cdot1$",
                   "$\\frac{\\delta E}{\\delta w_{j,k}} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta \\epsilon_k}\\cdot\\frac{\\delta \\epsilon_k}{\\delta w_{j,k}}$",
                      "$\\frac{\\delta E}{\\delta b_k} = \\frac{\\delta E}{\\delta O}\\cdot\\frac{\\delta O}{\\delta \\epsilon_k}\\cdot1$
                   ")
values$lr <- c("$\\varphi(2\\lambda_{i})$","0.1","0.01","0.01","0.01")
colnames(values) <- c("Initial values (SD)","Derivative","Lerning rate")
kable(values)

```

$\epsilon_j$ and $\epsilon_k$ denotes the summed input to the sigmoid functions, and $H_j$ is the output of the hidden layer sigmoid functions. $\varphi$ denotes the density function to a normal distribution with mean = 0 and SD = 1.

**First training (Initial fit on a multiplicative scale)**
In the first training, all activation functions, $f_k$ and $f_j$, are sigmoid functions, $\frac{1}{1-e^{-(b + w X)}}$ and the following derivatives hold:

$\frac{\delta E}{\delta O} = O - Y, \frac{\delta O}{\delta \epsilon_k} = O(1-O), \frac{\delta \epsilon_k}{\delta w_{j,k}} = H_je^{w_{j,k}}, \frac{\delta \epsilon_k}{\delta H_{j}} = e^{w_{j,k}}, \frac{\delta H_j}{\delta \epsilon_j} = H_j\cdot(1-H_j), \frac{\delta \epsilon_j}{\delta w_{i,j}}=X_i\lambda_ie^{w_{i,j}}, \frac{\delta \epsilon_j}{\delta \lambda_i}=X_ie^{w_{i,j}}$

**Second traning (Transfer learning to an additive scale)**
We use the model from the first training to transfer it to a model where the activation function for the output layer. $f_k(z)$ is slowly reweighted from the multiplicative sigmoid function into an additive modified hard sigmoid function, where z = 0 if z < -2, z = $\frac{z+2}{4}$ if z is between -2 and 2, and 1 if z > 2. The transfer is done using $(1-epoch/epochs)\cdot sigmoid(z)+(epoch/epochs)\cdot hardsigmoid(z)$. For the second additive fit, the following derivatives hold:

$\frac{\delta E}{\delta O} = O - Y, \frac{\delta O}{\delta \epsilon_k} = 1$ if $O$ > -2 and $O$ < 2 otherwise 0, $\frac{\delta \epsilon_k}{\delta w_{j,k}} = H_je^{w_{j,k}}, \frac{\delta \epsilon_k}{\delta H_{j}} = e^{w_{j,k}}, \frac{\delta H_j}{\delta \epsilon_j} = 1$ if $H_j$ > -2 and $H_j$ < 2 otherwise 0, $\frac{\delta \epsilon_j}{\delta w_{i,j}}=X_i\lambda_ie^{w_{i,j}}, \frac{\delta \epsilon_j}{\delta \lambda_i}=X_ie^{w_{i,j}}$


\newpage

### Toy examples
Below we show 3 data generating processes and the results returned by SCL. The figures show the probability. E.g. the number on the arrow into smoking (S) is $P(S)$ or the prevalence, the number on the arrow from smoking to mouth cancer (MC) is $P(MC|S=1)-P(MC|S=0)$ or the absolute increased risk of mouth cancer due to smoking. The box shows the proportion exposed to the exposure on the 1st axis and the proportion of these getting moutn cancer on the 2nd axis. 

![Toy example A](Figures/S_1_A.png){width=40%}
![Toy example A](Figures/Excess_SCL_1.png){width=45%}

SCL identifies a baseline risk of 10% shown with U_B at 0.1 at the 2nd axis, just as the data generating process was from $U_1$. One exposure was relevant for an increased risk - namely S (smoking). We see that 40% (1-0.6) are exposed to smoking (also as the data generating process was), and those exposed has a 30% (0.4-0.1) increased risk of the outcome as shown on the 2nd axis equivalent to the data generating process.



![Toy example B](Figures/S_1_B.png){width=40%}
![Toy example B](Figures/Excess_SCL_2.png){width=45%}

This data generating process shows two independent causes. The added risk due to asbestos (A) and smoking (S) are simply added in the double exposed group.


![Toy example D](Figures/S_1_D.png){width=40%}
![Toy example D](Figures/Excess_SCL_4.png){width=45%}

In this example, individuals only get mouth cancer if they have both asbestos (A) and smoking (S) with a certain probability (70%). The results of SCL represents the data generating process.

\newpage

### Theoretical expectations to the motivating example
$P(Y|U)=0.05$

$P(Y|MutationX,Airpollution)=0.1$

$P(MutationX,Airpollution)=(0.05\cdot0.95)\cdot(0.2\cdot0.3+0.2)=$ `r (0.05*0.95)*(0.2*0.3+0.2)`

$P(Y|NotNonSmoking,LDL,NightShift)=0.15$

$P(NotNonSmoking,LDL,NightShift)=(1-(0.8-0.2\cdot0.2))\cdot(0.3+0.02\cdot0.15)\cdot(0.2+0.2\cdot0.1)=$ `r (1-(0.8-0.2*0.2))*(0.3+0.02*0.15)*(0.2+0.2*0.1)`

$P(Y) =(1- (1 - P(Y|U)) \cdot  (1 - P(Y|MutationX,Airpollution)\cdot P(MutationX,Airpollution)) \cdot (1 - P(Y|NotNonSmoking,LDL,NightShift)\cdot P(Smoking,LDL,NightShift)) )=$ `r (1- (1-0.05) * (1-0.1 * (0.05*0.95)*(0.2*0.3+0.2)) * (1-0.15* (0.8-0.2*0.2)*(0.3+0.02*0.15)*(0.2+0.2*0.1)))   `

$\frac{P(Y|MutationX,Airpollution)\cdot P(MutationX,Airpollution)}{P(Y)}=$ `r (0.1 * (0.05*0.95)*(0.2*0.3+0.2)) / (1- (1-0.05) * (1-0.1 * (0.05*0.95)*(0.2*0.3+0.2)) * (1-0.15* (1-(0.8-0.2*0.2))*(0.3+0.02*0.15)*(0.2+0.2*0.1))) `

$\frac{P(Y| Not Non Smoking,LDL,Night Shift) \cdot P(NotNonSmoking,LDL,Night Shift)}{P(Y)}=$ `r (0.15* (1-(0.8-0.2*0.2))*(0.3+0.02*0.15)*(0.2+0.2*0.1)) / ((1- (1-0.05) * (1-0.1 * (0.05*0.95)*(0.2*0.3+0.2)) * (1-0.15* (0.8-0.2*0.2)*(0.3+0.02*0.15)*(0.2+0.2*0.1))))`

\newpage

### Repeated simulations
When we rerun the data generating process and the analytical SCL model, we get the following plot 2s:

![](Figures/Redo/SCL_redo_1.png){width=33%}
![](Figures/Redo/SCL_redo_2.png){width=33%}
![](Figures/Redo/SCL_redo_3.png){width=33%}
![](Figures/Redo/SCL_redo_4.png){width=33%}
![](Figures/Redo/SCL_redo_5.png){width=33%}
![](Figures/Redo/SCL_redo_6.png){width=33%}
![](Figures/Redo/SCL_redo_7.png){width=33%}
![](Figures/Redo/SCL_redo_8.png){width=33%}
![](Figures/Redo/SCL_redo_9.png){width=33%}
![](Figures/Redo/SCL_redo_10.png){width=33%}
![](Figures/Redo/SCL_redo_11.png){width=33%}
![](Figures/Redo/SCL_redo_12.png){width=33%}
![](Figures/Redo/SCL_redo_13.png){width=33%}
![](Figures/Redo/SCL_redo_14.png){width=33%}
![](Figures/Redo/SCL_redo_15.png){width=33%}
![](Figures/Redo/SCL_redo_16.png){width=33%}
![](Figures/Redo/SCL_redo_17.png){width=33%}
![](Figures/Redo/SCL_redo_18.png){width=33%}
![](Figures/Redo/SCL_redo_19.png){width=33%}
![](Figures/Redo/SCL_redo_20.png){width=33%}




\newpage


### Various number of epochs

**10 epochs for the non-linear fit and for the linear fit**


![](Figures/Epochs/epochs_10.png){width=85%}

\newpage

**50 epochs for the non-linear fit and for the linear fit**


![](Figures/Epochs/epochs_50.png){width=85%}

\newpage

**100 epochs for the non-linear fit and for the linear fit** 


![](Figures/Epochs/epochs_100.png){width=85%}

\newpage

**200 epochs for the non-linear fit and for the linear fit**


![](Figures/Epochs/epochs_200.png){width=85%}

\newpage

**500 epochs for the non-linear fit and for the linear fit**


![](Figures/Epochs/epochs_500.png){width=85%}





\newpage

-->

\newpage

# References
